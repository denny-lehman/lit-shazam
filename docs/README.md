## Documents we used!

    | | Sentence #  | Word    | POS   | Tag   |

| id | Document     | description | link |
|---:|:-------------|:------------|:------|
| 2 | Project Shared Drive | The google drive cloud repository for all of our non-code work | https://drive.google.com/drive/folders/1x0v5jpTWA9mk2K9WgjXEYvZ7t877OsPd?usp=sharing |
| 3 | Lit-Shazam Status report | the powerpoint we used to address ideas and questions when meeting with Mark | https://docs.google.com/presentation/d/1LZcgV0HZ5oSkdv_Y_m6WQXlBxWf5CRCEUZxKQ0Gj6Wc/edit?usp=sharing | 
| 4 | Development Pipeline | A google drawing of the proposed and implemented development pipeline for the project | https://docs.google.com/drawings/d/1N66EwyiHsmB4gy-E9-8KOX7ZH0S2BiEy9yVOcrLUx44/edit?usp=sharing |



## Papers we like!

|id | Title | Link | Description|
|---|---|---|---|
| 1 | Attention is all you need | https://arxiv.org/pdf/1706.03762.pdf | The transformer paper |
| 2 | BERT | https://arxiv.org/pdf/1810.04805v1.pdf | The BERT paper|
| 3 | Visual Literature Timeline | https://pedagoglog.wordpress.com/2016/05/06/american-literature-timeline/ | A peer through time to base our authors and their temporal relationships | 
| 4 | Overview of RoBERTa| https://www.geeksforgeeks.org/overview-of-roberta-model/ | Roberta is a better trained BERT model|
| 5 | How to read a paper | http://ccr.sigcomm.org/online/files/p83-keshavA.pdf | A good guide on reading all these papers we like| 
| 6 | RoBERTa | https://arxiv.org/pdf/1907.11692.pdf | The RoBERTa paper - a better BERT| 

Authorship Attribution Papers
|id | Title | Link | Description|
|---|---|---|---|
| 1 | Function words for AA | https://arxiv.org/pdf/1406.4469.pdf | An important paper because function words are great at authorship attribution because they - are subconcious, span genres.|
| 2 | Micro Message AA | https://aclanthology.org/D13-1193.pdf | Finding an authors unique signature when the text is the size of a tweet!| 
| 3 | CNNs for AA in short text | https://aclanthology.org/E17-2106.pdf | High Model interpretability thanks to CNN architecture | 



## Code of interest!

|id | Title | Link | Description|
|---|---|---|---|
| 1 | Out of core processing | https://scikit-learn.org/stable/auto_examples/applications/plot_out_of_core_classification.html#sphx-glr-auto-examples-applications-plot-out-of-core-classification-py | when text can't fit into memory or new words are found in a corpus |

